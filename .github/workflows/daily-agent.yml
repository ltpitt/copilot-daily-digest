name: Daily Copilot Digest

on:
  schedule:
    - cron: '14 23 * * *'  # Daily at 1 PM UTC
  workflow_dispatch:     # Allows manual triggering

permissions:
  contents: write        # Required to push changes
  pull-requests: write   # Required for copilot agent
  issues: write          # Required to create issues

jobs:
  fetch-and-detect:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # Fetch all content sources
      - name: Fetch GitHub Docs
        run: python scraper/fetch_docs.py
      
      - name: Fetch GitHub Blog (RSS)
        run: python scraper/fetch_blog.py
      
      - name: Fetch YouTube Videos (RSS)
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: python scraper/fetch_youtube.py
      
      - name: Fetch Training Resources
        run: python scraper/fetch_trainings.py
      
      # Detect changes
      - name: Detect Changes
        id: changes
        run: |
          python scraper/detect_changes.py > changes.txt
          cat changes.txt
          
          # Check if there are changes
          if grep -q '"has_changes": true' data/changes-summary.json; then
            echo "HAS_CHANGES=true" >> $GITHUB_OUTPUT
          else
            echo "HAS_CHANGES=false" >> $GITHUB_OUTPUT
          fi
      
      # Commit data files to main
      - name: Commit Data Files
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          git commit -m "chore: update scraped data [$(date +'%Y-%m-%d')]"
          git push
      
      # Update any open content PRs to avoid merge conflicts
      - name: Update Open Content PRs
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Find open PRs with "Content update" in title
          OPEN_PRS=$(gh pr list --state open --json number,title --jq '.[] | select(.title | contains("Content update")) | .number')
          
          if [ -n "$OPEN_PRS" ]; then
            echo "Found open content PRs: $OPEN_PRS"
            for PR_NUMBER in $OPEN_PRS; do
              echo "Updating PR #$PR_NUMBER with latest main..."
              
              # Get PR branch name
              PR_BRANCH=$(gh pr view "$PR_NUMBER" --json headRefName --jq '.headRefName')
              
              # Checkout PR branch and merge main
              git fetch origin "$PR_BRANCH"
              git checkout "$PR_BRANCH"
              
              # Merge main (use --theirs for metadata conflicts)
              if git merge main -m "chore: merge main to resolve conflicts"; then
                echo "‚úì Merged main successfully"
              else
                # Resolve conflicts by taking newer metadata from main
                git checkout --theirs data/metadata.json data/changes-summary.json 2>/dev/null || true
                git add data/metadata.json data/changes-summary.json 2>/dev/null || true
                git commit -m "chore: merge main and resolve metadata conflicts" 2>/dev/null || true
              fi
              
              # Push updated branch
              git push origin "$PR_BRANCH" || echo "‚ö† Failed to push updates to PR #$PR_NUMBER"
              
              # Comment on PR
              gh pr comment "$PR_NUMBER" --body "ü§ñ Auto-updated branch with latest data from main to resolve merge conflicts."
            done
            
            # Return to main
            git checkout main
          else
            echo "No open content PRs found to update"
          fi
      
      # Trigger Publisher Agent (only if changes detected)
      - name: Create Issue for Publisher Agent
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        id: create_issue
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Read change summary
          SUMMARY=$(cat data/changes-summary.json | jq -r '.summary_text')
          
          # Create issue for Publisher agent and capture the URL
          ISSUE_URL=$(gh issue create \
            --title "üì∞ Content Update Required - $(date +'%Y-%m-%d')" \
            --body "## Changes Detected

          $SUMMARY

          ---

          Please synthesize **modular, topic-focused** content that helps engineers stay current with GitHub Copilot.

          ### Data Sources Available
          - **Documentation**: \`data/docs/*.md\` (14 files) - Official GitHub Copilot docs
          - **Blog Posts**: \`data/blog/*.json\` (19+ files) - Full HTML content with tutorials, best practices, announcements
          - **Videos**: \`data/videos/*.json\` (6+ files) - Curated Copilot/AI videos from GitHub channel
          - **Trainings**: \`data/trainings/*.json\` (7+ files) - Curated courses from GitHub Skills, Microsoft Learn, Certifications, Udemy
          - **Change Detection**: \`data/changes-summary.json\` - What changed since last scrape (with diff summaries)
          - **Version History**: \`data/metadata.json\` - \`doc_versions[].history[]\` tracks all changes with timestamps

          ### Task: Generate 7 Modular Content Files

          **CRITICAL**: Each file is **self-contained** and **topic-focused**. No mixing of concerns.

          #### 1. \`content/README.md\` - Navigation Hub (50-100 lines max)
          - Central index linking to all other files
          - Current stats (N updates, N videos, N trainings)
          - Official resource links
          - **NO detailed content** - only links and summaries

          #### 2. \`content/GETTING-STARTED.md\` - Quick Start + Best Practices (200-300 lines)
          - 5-minute quick setup tutorial
          - Extract 5-7 actionable best practices from blog posts
          - Each tip: ‚ùå/‚úÖ comparison + concrete example + source link
          - Links to VIDEOS.md, TRAININGS.md, WHATS-NEW.md for next steps

          #### 3. \`content/WHATS-NEW.md\` - Latest Updates (300-400 lines)
          - **This Week**: TOP 3-5 significant changes from last 7 days
          - **This Month**: TOP 10 significant changes from last 30 days
          - Auto-expires content older than 30 days (point to CHANGELOG.md)
          - Format: Feature name + what's new + why it matters + get started links

          #### 4. \`content/VIDEOS.md\` - Video Library
          - **DO NOT MODIFY** - Auto-generated by \`scraper/generate_videos.py\`

          #### 5. \`content/TRAININGS.md\` - Courses & Certifications (400-500 lines)
          - Group by provider: GitHub Skills, Microsoft Learn, Certifications, Curated
          - Each course: Level, duration, cost, description, what you'll learn
          - Learning paths for beginners and advanced users
          - Quality filters: Official always included, Udemy only if rating >= 4.5

          #### 6. \`content/CHANGELOG.md\` - Complete Historical Timeline (unlimited)
          - Reverse chronological, month-by-month
          - ALL updates: blog posts, doc changes, videos
          - Never remove old entries (complete historical record)

          #### 7. \`content/COMMANDS.md\` - Quick Reference (200-300 lines)
          - Slash commands table (extract from copilot-chat.md)
          - Keyboard shortcuts by IDE (extract from copilot-getting-started.md)
          - Chat variables table (extract from copilot-chat.md)
          - Chat participants table (extract from copilot-chat.md)

          #### 8. \`content/REFERENCE.md\` - Complete Docs Index (100-200 lines)
          - All 14 docs grouped by category
          - Brief description for each
          - Last updated timestamps from metadata.json
          - Links to external resources

          ### Output Requirements
          - **Modular**: Each file has ONE clear purpose
          - **Scannable**: Use tables, bullets, emojis sparingly
          - **Actionable**: Every tip has concrete examples
          - **Linked**: Every mention links to source
          - **Fresh**: Auto-expire old content in WHATS-NEW.md

          **Instructions file**: \`.github/copilot-instructions.md\` has complete generation rules for each file

          Create a PR with all 7 files (VIDEOS.md already exists, don't touch it).")
          
          # Extract issue number from URL
          ISSUE_NUMBER=$(echo "$ISSUE_URL" | sed -n 's|.*/issues/\([0-9]*\)$|\1|p')
          echo "ISSUE_NUMBER=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "Created issue #$ISSUE_NUMBER: $ISSUE_URL"
      
      # Install and use Copilot CLI to work on the issue
      - name: Delegate to Copilot CLI
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          ISSUE_NUMBER="${{ steps.create_issue.outputs.ISSUE_NUMBER }}"
          
          # Install Copilot CLI
          echo "Installing GitHub Copilot CLI..."
          npm install -g @github/copilot
          
          # Use Copilot CLI in programmatic mode to work on the issue
          echo "Delegating work to Copilot CLI for issue #$ISSUE_NUMBER..."
          copilot -p "I've been assigned issue #$ISSUE_NUMBER in this repository. Please start working on it by creating a new branch and implementing the requested changes. When done, create a pull request." \
            --allow-tool 'write' \
            --allow-tool 'shell(git)' \
            --deny-tool 'shell(git push)' \
            --deny-tool 'shell(rm)'
          
          echo "‚úì Copilot CLI task delegated for issue #$ISSUE_NUMBER"
      
      - name: No Changes Detected
        if: steps.changes.outputs.HAS_CHANGES == 'false'
        run: echo "‚ÑπÔ∏è No changes detected. Skipping content generation."
