name: Daily Copilot Digest

on:
  schedule:
    - cron: '0 13 * * *'  # Daily at 1 PM UTC
  workflow_dispatch:     # Allows manual triggering

permissions:
  contents: write        # Required to push changes
  pull-requests: write   # Required for copilot agent
  issues: write          # Required to create issues

jobs:
  fetch-and-detect:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      # Fetch all content sources
      - name: Fetch GitHub Docs
        run: python scraper/fetch_docs.py
      
      - name: Fetch GitHub Blog (RSS)
        run: python scraper/fetch_blog.py
      
      - name: Fetch YouTube Videos (RSS)
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: python scraper/fetch_youtube.py
      
      # Detect changes
      - name: Detect Changes
        id: changes
        run: |
          python scraper/detect_changes.py > changes.txt
          cat changes.txt
          
          # Check if there are changes
          if grep -q '"has_changes": true' data/changes-summary.json; then
            echo "HAS_CHANGES=true" >> $GITHUB_OUTPUT
          else
            echo "HAS_CHANGES=false" >> $GITHUB_OUTPUT
          fi
      
      # Commit data files
      - name: Commit Data Files
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          git commit -m "chore: update scraped data [$(date +'%Y-%m-%d')]"
          git push
      
      # Trigger Publisher Agent (only if changes detected)
      - name: Create Issue for Publisher Agent
        if: steps.changes.outputs.HAS_CHANGES == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Read change summary
          SUMMARY=$(cat data/changes-summary.json | jq -r '.summary_text')
          
          # Create issue for Publisher agent
          gh issue create \
            --title "üì∞ Content Update Required - $(date +'%Y-%m-%d')" \
            --body "## Changes Detected

          $SUMMARY

          @copilot Please generate updated content files from the latest data in \`data/\` directory.

          **What to do:**
          1. Read all data from \`data/docs/\`, \`data/blog/\`, \`data/videos/\`
          2. Generate updated \`content/README.md\` (main digest)
          3. Generate updated \`content/changelog.md\` (feature timeline)
          4. Generate updated \`content/cheatsheet.md\` (quick reference)
          5. Generate updated \`content/videos.md\` (video library)
          6. Create a PR with all changes

          **Assigned to:** Publisher Agent" \
            --label "automation,content-update"
      
      - name: No Changes Detected
        if: steps.changes.outputs.HAS_CHANGES == 'false'
        run: echo "‚ÑπÔ∏è No changes detected. Skipping content generation."
